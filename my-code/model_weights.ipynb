{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to organize images in: E:\\LinearStyleTransfer-master\\LinearStyleTransfer\\data\\styled_outputs\\style_21\n",
      "\n",
      "Organization complete! Summary:\n",
      "Sigma 5: 16 images moved\n",
      "Sigma 10: 16 images moved\n",
      "Sigma 15: 16 images moved\n",
      "Sigma 20: 16 images moved\n",
      "Sigma 25: 16 images moved\n",
      "Sigma 30: 16 images moved\n",
      "Sigma 40: 16 images moved\n",
      "Sigma 45: 16 images moved\n",
      "Sigma 50: 16 images moved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:51: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:51: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\Ishaan\\AppData\\Local\\Temp\\ipykernel_6796\\2223061107.py:51: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  source_directory = \"E:\\LinearStyleTransfer-master\\LinearStyleTransfer\\data\\styled_outputs\\style_21\"  # Replace with your actual path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def organize_by_sigma(source_dir):\n",
    "    \"\"\"\n",
    "    Organizes images in the source directory into subdirectories based on sigma levels.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): Path to the directory containing the images\n",
    "        \n",
    "    The function will:\n",
    "    1. Create subdirectories for each sigma level\n",
    "    2. Move each image to its corresponding sigma directory\n",
    "    3. Print progress and summary information\n",
    "    \"\"\"\n",
    "    # Convert the source directory to a Path object for easier handling\n",
    "    source_path = Path(source_dir)\n",
    "    \n",
    "    # Dictionary to keep track of how many files are moved to each sigma level\n",
    "    files_moved = {}\n",
    "    \n",
    "    # Iterate through all PNG files in the source directory\n",
    "    for image_file in source_path.glob('*.png'):\n",
    "        try:\n",
    "            # Extract the sigma level from the filename\n",
    "            # Filename format: XX_sigma_YY.png where YY is the sigma level\n",
    "            sigma_level = image_file.name.split('sigma_')[1].split('.')[0]\n",
    "            \n",
    "            # Create the sigma level directory if it doesn't exist\n",
    "            sigma_dir = source_path / f\"sigma_{sigma_level}\"\n",
    "            sigma_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Move the file to its sigma directory\n",
    "            shutil.move(str(image_file), str(sigma_dir / image_file.name))\n",
    "            \n",
    "            # Update our counter\n",
    "            files_moved[sigma_level] = files_moved.get(sigma_level, 0) + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file.name}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nOrganization complete! Summary:\")\n",
    "    for sigma, count in sorted(files_moved.items(), key=lambda x: int(x[0])):\n",
    "        print(f\"Sigma {sigma}: {count} images moved\")\n",
    "    \n",
    "    return files_moved\n",
    "\n",
    "# Path to your directory containing the images\n",
    "source_directory = \"E:\\LinearStyleTransfer-master\\LinearStyleTransfer\\data\\styled_outputs\\style_21\"  # Replace with your actual path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the source directory exists\n",
    "    if not os.path.exists(source_directory):\n",
    "        print(f\"Error: Directory '{source_directory}' does not exist!\")\n",
    "    else:\n",
    "        print(f\"Starting to organize images in: {source_directory}\")\n",
    "        organize_by_sigma(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 04:48:25.974844: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 04:48:25.978124: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 04:48:25.988231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730848706.005246  278137 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730848706.010372  278137 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 04:48:26.028304: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorFlow model...\n",
      "Extracting and saving weights...\n",
      "Saved rev_block1_conv2_kernel_0 with shape (3, 3, 64, 64)\n",
      "Saved rev_block1_conv2_bias_0 with shape (64,)\n",
      "Saved rev_block1_conv1_kernel_0 with shape (3, 3, 64, 3)\n",
      "Saved rev_block1_conv1_bias_0 with shape (3,)\n",
      "\n",
      "Defining PyTorch model...\n",
      "\n",
      "Loading weights into PyTorch model...\n",
      "Loaded weights for conv1_2.weight\n",
      "Loaded weights for conv1_2.bias\n",
      "Loaded weights for conv1_1.weight\n",
      "Loaded weights for conv1_1.bias\n",
      "\n",
      "Conversion complete!\n",
      "\n",
      "Model weights saved to models/dec_r11.pth\n",
      "\n",
      "Verifying the output...\n",
      "Output shape: torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730848708.996150  278137 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Load TensorFlow Model and Extract Weights\n",
    "# Define paths\n",
    "model_path = '/home/sunayana/Documents/LinearStyleTransfer/models/vgg_r11/tensorflow2-decoder-v1'\n",
    "weights_dir = \"./weights/dec_r11\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "print(\"Loading TensorFlow model...\")\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "\n",
    "print(\"Extracting and saving weights...\")\n",
    "# Iterate over the model variables and save weights as NumPy arrays\n",
    "for var in loaded_model.variables:\n",
    "    weight_name = var.name.replace(\"/\", \"_\").replace(\":\", \"_\")  # Clean up the variable name for saving\n",
    "    np.save(os.path.join(weights_dir, f\"{weight_name}.npy\"), var.numpy())\n",
    "    print(f\"Saved {weight_name} with shape {var.shape}\")\n",
    "\n",
    "# Step 2: Define the Equivalent PyTorch Decoder Model\n",
    "print(\"\\nDefining PyTorch model...\")\n",
    "\n",
    "class VGGDecoderR11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGDecoderR11, self).__init__()\n",
    "        # Example model architecture for the decoder\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.relu1_2(x)\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.relu1_1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "torch_model = VGGDecoderR11()\n",
    "\n",
    "# Step 3: Load the Weights into the PyTorch Model\n",
    "print(\"\\nLoading weights into PyTorch model...\")\n",
    "\n",
    "def load_weights(torch_model, weights_dir):\n",
    "    # Weight files mapping according to extracted TensorFlow variables\n",
    "    weight_files = {\n",
    "        \"conv1_2.weight\": \"rev_block1_conv2_kernel_0.npy\",\n",
    "        \"conv1_2.bias\": \"rev_block1_conv2_bias_0.npy\",\n",
    "        \"conv1_1.weight\": \"rev_block1_conv1_kernel_0.npy\",\n",
    "        \"conv1_1.bias\": \"rev_block1_conv1_bias_0.npy\"\n",
    "    }\n",
    "\n",
    "    for param_name, npy_file in weight_files.items():\n",
    "        # Load the numpy file\n",
    "        param_weight = torch.from_numpy(np.load(os.path.join(weights_dir, npy_file)))\n",
    "        \n",
    "        # Transpose if needed to match PyTorch dimension format\n",
    "        if 'weight' in param_name and len(param_weight.shape) == 4:\n",
    "            # TensorFlow uses (H, W, in_channels, out_channels) whereas PyTorch uses (out_channels, in_channels, H, W)\n",
    "            param_weight = param_weight.permute(3, 2, 0, 1)\n",
    "        \n",
    "        # Get the parameter (either weight or bias) from the model\n",
    "        param = getattr(torch_model, param_name.split(\".\")[0])\n",
    "        \n",
    "        # Assign the weights to the PyTorch layer\n",
    "        if 'weight' in param_name:\n",
    "            param.weight.data.copy_(param_weight)\n",
    "        elif 'bias' in param_name:\n",
    "            param.bias.data.copy_(param_weight)\n",
    "        \n",
    "        print(f\"Loaded weights for {param_name}\")\n",
    "\n",
    "# Load weights into the PyTorch model\n",
    "load_weights(torch_model, weights_dir)\n",
    "\n",
    "print(\"\\nConversion complete!\")\n",
    "\n",
    "# Step 4: Save the PyTorch Model Weights\n",
    "output_path = \"models/dec_r11.pth\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "torch.save(torch_model.state_dict(), output_path)\n",
    "print(f\"\\nModel weights saved to {output_path}\")\n",
    "\n",
    "# Optional: Verify the output\n",
    "print(\"\\nVerifying the output...\")\n",
    "\n",
    "# Create a random input tensor to test the model\n",
    "input_tensor = torch.randn(1, 64, 224, 224)  # Batch size 1, 64 channels, 224x224 image\n",
    "output = torch_model(input_tensor)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numpy files and converting to PyTorch tensors...\n",
      "Loaded conv1_2.weight with shape torch.Size([64, 64, 3, 3])\n",
      "Loaded conv1_2.bias with shape torch.Size([64])\n",
      "Loaded conv1_1.weight with shape torch.Size([3, 64, 3, 3])\n",
      "Loaded conv1_1.bias with shape torch.Size([3])\n",
      "\n",
      "Model weights saved to ./models/dec_r11.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory containing the extracted weights in .npy files\n",
    "weights_dir = \"./weights/dec_r11\"  # Replace with the correct path to your weights directory\n",
    "\n",
    "# List of numpy weight files and corresponding PyTorch model parameters\n",
    "weight_files = {\n",
    "    \"conv1_2.weight\": \"rev_block1_conv2_kernel_0.npy\",\n",
    "    \"conv1_2.bias\": \"rev_block1_conv2_bias_0.npy\",\n",
    "    \"conv1_1.weight\": \"rev_block1_conv1_kernel_0.npy\",\n",
    "    \"conv1_1.bias\": \"rev_block1_conv1_bias_0.npy\"\n",
    "}\n",
    "\n",
    "# Step 1: Create an empty PyTorch state dictionary\n",
    "state_dict = {}\n",
    "\n",
    "# Step 2: Iterate over the weight files and add them to the state dictionary\n",
    "print(\"Loading numpy files and converting to PyTorch tensors...\")\n",
    "for param_name, npy_file in weight_files.items():\n",
    "    # Construct the full path to the .npy file\n",
    "    file_path = os.path.join(weights_dir, npy_file)\n",
    "    \n",
    "    # Load the numpy array from file\n",
    "    numpy_array = np.load(file_path)\n",
    "    \n",
    "    # Convert numpy array to PyTorch tensor\n",
    "    tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "    # Transpose if necessary to match PyTorch's dimension format\n",
    "    if \"weight\" in param_name and len(tensor.shape) == 4:  # Convolutional weights are 4D\n",
    "        tensor = tensor.permute(3, 2, 0, 1)  # TensorFlow uses (H, W, In_C, Out_C), PyTorch uses (Out_C, In_C, H, W)\n",
    "\n",
    "    # Add tensor to the state dictionary\n",
    "    state_dict[param_name] = tensor\n",
    "    print(f\"Loaded {param_name} with shape {tensor.shape}\")\n",
    "\n",
    "# Step 3: Save the state dictionary to a .pth file\n",
    "output_path = \"./models/dec_r11.pth\"  # Replace with your desired output path\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "torch.save(state_dict, output_path)\n",
    "print(f\"\\nModel weights saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorFlow model...\n",
      "Extracting and saving weights...\n",
      "Saved block1_conv1_kernel_0 with shape (3, 3, 3, 64)\n",
      "Saved block1_conv1_bias_0 with shape (64,)\n",
      "Saved block1_conv2_kernel_0 with shape (3, 3, 64, 64)\n",
      "Saved block1_conv2_bias_0 with shape (64,)\n",
      "Saved block2_conv1_kernel_0 with shape (3, 3, 64, 128)\n",
      "Saved block2_conv1_bias_0 with shape (128,)\n",
      "Saved block2_conv2_kernel_0 with shape (3, 3, 128, 128)\n",
      "Saved block2_conv2_bias_0 with shape (128,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "model_path = '/home/sunayana/Documents/LinearStyleTransfer/models/vgg_r21/tensorflow-encoder-v1'  # Replace with your TensorFlow model path\n",
    "weights_dir = \"./weights/vgg_r21\"  # Directory to store the weights as .npy files\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: Load TensorFlow Model and Extract Weights\n",
    "print(\"Loading TensorFlow model...\")\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "\n",
    "print(\"Extracting and saving weights...\")\n",
    "# Iterate over the model variables and save weights as NumPy arrays\n",
    "for var in loaded_model.variables:\n",
    "    weight_name = var.name.replace(\"/\", \"_\").replace(\":\", \"_\")  # Clean up the variable name for saving\n",
    "    np.save(os.path.join(weights_dir, f\"{weight_name}.npy\"), var.numpy())\n",
    "    print(f\"Saved {weight_name} with shape {var.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining PyTorch model...\n",
      "\n",
      "Loading weights into PyTorch model...\n",
      "Loaded conv1_1.weight with shape torch.Size([64, 3, 3, 3])\n",
      "Loaded conv1_1.bias with shape torch.Size([64])\n",
      "Loaded conv1_2.weight with shape torch.Size([64, 64, 3, 3])\n",
      "Loaded conv1_2.bias with shape torch.Size([64])\n",
      "Loaded conv2_1.weight with shape torch.Size([128, 64, 3, 3])\n",
      "Loaded conv2_1.bias with shape torch.Size([128])\n",
      "\n",
      "Model weights saved to ./models/vgg_r21.pth\n",
      "\n",
      "Verifying the output...\n",
      "Output shape: torch.Size([1, 128, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Define the Equivalent PyTorch Encoder Model for r21\n",
    "print(\"\\nDefining PyTorch model...\")\n",
    "\n",
    "class VGGEncoderR21(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGEncoderR21, self).__init__()\n",
    "        # Example model architecture matching the TensorFlow model for r21 encoder\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        # You can add more layers if required, depending on the TensorFlow model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.relu1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.relu1_2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.relu2_1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "torch_model = VGGEncoderR21()\n",
    "\n",
    "# Step 2: Load the Weights into the PyTorch Model\n",
    "print(\"\\nLoading weights into PyTorch model...\")\n",
    "\n",
    "# Directory containing the extracted weights in .npy files\n",
    "weights_dir = \"./weights/vgg_r21\"  # Replace with your path to the weights directory\n",
    "\n",
    "# List of numpy weight files and corresponding PyTorch model parameters\n",
    "weight_files = {\n",
    "    \"conv1_1.weight\": \"block1_conv1_kernel_0.npy\",\n",
    "    \"conv1_1.bias\": \"block1_conv1_bias_0.npy\",\n",
    "    \"conv1_2.weight\": \"block1_conv2_kernel_0.npy\",\n",
    "    \"conv1_2.bias\": \"block1_conv2_bias_0.npy\",\n",
    "    \"conv2_1.weight\": \"block2_conv1_kernel_0.npy\",\n",
    "    \"conv2_1.bias\": \"block2_conv1_bias_0.npy\"\n",
    "}\n",
    "\n",
    "# Step 3: Create an empty PyTorch state dictionary\n",
    "state_dict = {}\n",
    "\n",
    "# Step 4: Iterate over the weight files and add them to the state dictionary\n",
    "for param_name, npy_file in weight_files.items():\n",
    "    # Construct the full path to the .npy file\n",
    "    file_path = os.path.join(weights_dir, npy_file)\n",
    "    \n",
    "    # Load the numpy array from file\n",
    "    numpy_array = np.load(file_path)\n",
    "    \n",
    "    # Convert numpy array to PyTorch tensor\n",
    "    tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "    # Transpose if necessary to match PyTorch's dimension format\n",
    "    if \"weight\" in param_name and len(tensor.shape) == 4:  # Convolutional weights are 4D\n",
    "        tensor = tensor.permute(3, 2, 0, 1)  # TensorFlow uses (H, W, In_C, Out_C), PyTorch uses (Out_C, In_C, H, W)\n",
    "\n",
    "    # Add tensor to the state dictionary\n",
    "    state_dict[param_name] = tensor\n",
    "    print(f\"Loaded {param_name} with shape {tensor.shape}\")\n",
    "\n",
    "# Step 5: Load the state dictionary into the PyTorch model\n",
    "torch_model.load_state_dict(state_dict)\n",
    "\n",
    "# Step 6: Save the state dictionary to a .pth file\n",
    "output_path = \"./models/vgg_r21.pth\"  # Replace with your desired output path\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "torch.save(state_dict, output_path)\n",
    "print(f\"\\nModel weights saved to {output_path}\")\n",
    "\n",
    "# Optional: Verify the output\n",
    "print(\"\\nVerifying the output...\")\n",
    "# Create a random input tensor to test the model\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 channels, 224x224 image\n",
    "output = torch_model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorFlow model...\n",
      "Extracting and saving weights...\n",
      "Saved rev_block2_conv2_kernel_0 with shape (3, 3, 128, 128)\n",
      "Saved rev_block2_conv2_bias_0 with shape (128,)\n",
      "Saved rev_block2_conv1_kernel_0 with shape (3, 3, 128, 64)\n",
      "Saved rev_block2_conv1_bias_0 with shape (64,)\n",
      "Saved rev_block1_conv2_kernel_0 with shape (3, 3, 64, 64)\n",
      "Saved rev_block1_conv2_bias_0 with shape (64,)\n",
      "Saved rev_block1_conv1_kernel_0 with shape (3, 3, 64, 3)\n",
      "Saved rev_block1_conv1_bias_0 with shape (3,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "model_path = '/home/sunayana/Documents/LinearStyleTransfer/models/vgg_r21/tensorflow-decoder-v1'  # Replace with your TensorFlow model path\n",
    "weights_dir = \"./weights/dec_r21\"  # Directory to store the weights as .npy files\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: Load TensorFlow Model and Extract Weights\n",
    "print(\"Loading TensorFlow model...\")\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "\n",
    "print(\"Extracting and saving weights...\")\n",
    "# Iterate over the model variables and save weights as NumPy arrays\n",
    "for var in loaded_model.variables:\n",
    "    weight_name = var.name.replace(\"/\", \"_\").replace(\":\", \"_\")  # Clean up the variable name for saving\n",
    "    np.save(os.path.join(weights_dir, f\"{weight_name}.npy\"), var.numpy())\n",
    "    print(f\"Saved {weight_name} with shape {var.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining PyTorch model...\n",
      "\n",
      "Loading weights into PyTorch model...\n",
      "Loaded conv2_1.weight with shape torch.Size([64, 128, 3, 3])\n",
      "Loaded conv2_1.bias with shape torch.Size([64])\n",
      "Loaded conv1_2.weight with shape torch.Size([64, 64, 3, 3])\n",
      "Loaded conv1_2.bias with shape torch.Size([64])\n",
      "Loaded conv1_1.weight with shape torch.Size([3, 64, 3, 3])\n",
      "Loaded conv1_1.bias with shape torch.Size([3])\n",
      "\n",
      "Model weights saved to ./models/dec_r21.pth\n",
      "\n",
      "Verifying the output...\n",
      "Output shape: torch.Size([1, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Define the Equivalent PyTorch Decoder Model for r21\n",
    "print(\"\\nDefining PyTorch model...\")\n",
    "\n",
    "class VGGDecoderR21(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGDecoderR21, self).__init__()\n",
    "        # Example model architecture matching the TensorFlow model for r21 decoder\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.unpool1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        # You can add more layers if required, depending on the TensorFlow model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.relu2_1(x)\n",
    "        x = self.unpool1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.relu1_2(x)\n",
    "        x = self.conv1_1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch model\n",
    "torch_model = VGGDecoderR21()\n",
    "\n",
    "# Step 2: Load the Weights into the PyTorch Model\n",
    "print(\"\\nLoading weights into PyTorch model...\")\n",
    "\n",
    "# Directory containing the extracted weights in .npy files\n",
    "weights_dir = \"./weights/dec_r21\"  # Replace with your path to the weights directory\n",
    "\n",
    "# List of numpy weight files and corresponding PyTorch model parameters\n",
    "weight_files = {\n",
    "    \"conv2_1.weight\": \"rev_block2_conv1_kernel_0.npy\",\n",
    "    \"conv2_1.bias\": \"rev_block2_conv1_bias_0.npy\",\n",
    "    \"conv1_2.weight\": \"rev_block1_conv2_kernel_0.npy\",\n",
    "    \"conv1_2.bias\": \"rev_block1_conv2_bias_0.npy\",\n",
    "    \"conv1_1.weight\": \"rev_block1_conv1_kernel_0.npy\",\n",
    "    \"conv1_1.bias\": \"rev_block1_conv1_bias_0.npy\"\n",
    "}\n",
    "\n",
    "# Step 3: Create an empty PyTorch state dictionary\n",
    "state_dict = {}\n",
    "\n",
    "# Step 4: Iterate over the weight files and add them to the state dictionary\n",
    "for param_name, npy_file in weight_files.items():\n",
    "    # Construct the full path to the .npy file\n",
    "    file_path = os.path.join(weights_dir, npy_file)\n",
    "    \n",
    "    # Load the numpy array from file\n",
    "    numpy_array = np.load(file_path)\n",
    "    \n",
    "    # Convert numpy array to PyTorch tensor\n",
    "    tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "    # Transpose if necessary to match PyTorch's dimension format\n",
    "    if \"weight\" in param_name and len(tensor.shape) == 4:  # Convolutional weights are 4D\n",
    "        tensor = tensor.permute(3, 2, 0, 1)  # TensorFlow uses (H, W, In_C, Out_C), PyTorch uses (Out_C, In_C, H, W)\n",
    "\n",
    "    # Add tensor to the state dictionary\n",
    "    state_dict[param_name] = tensor\n",
    "    print(f\"Loaded {param_name} with shape {tensor.shape}\")\n",
    "\n",
    "# Step 5: Load the state dictionary into the PyTorch model\n",
    "torch_model.load_state_dict(state_dict)\n",
    "\n",
    "# Step 6: Save the state dictionary to a .pth file\n",
    "output_path = \"./models/dec_r21.pth\"  # Replace with your desired output path\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "torch.save(state_dict, output_path)\n",
    "print(f\"\\nModel weights saved to {output_path}\")\n",
    "\n",
    "# Optional: Verify the output\n",
    "print(\"\\nVerifying the output...\")\n",
    "# Create a random input tensor to test the model\n",
    "input_tensor = torch.randn(1, 128, 56, 56)  # Batch size 1, 128 channels, 56x56 feature map\n",
    "output = torch_model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorFlow model...\n",
      "Extracting and saving weights...\n",
      "Saved block1_conv1_kernel_0 with shape (3, 3, 3, 64)\n",
      "Saved block1_conv1_bias_0 with shape (64,)\n",
      "Saved block1_conv2_kernel_0 with shape (3, 3, 64, 64)\n",
      "Saved block1_conv2_bias_0 with shape (64,)\n",
      "Saved block2_conv1_kernel_0 with shape (3, 3, 64, 128)\n",
      "Saved block2_conv1_bias_0 with shape (128,)\n",
      "Saved block2_conv2_kernel_0 with shape (3, 3, 128, 128)\n",
      "Saved block2_conv2_bias_0 with shape (128,)\n",
      "Saved block3_conv1_kernel_0 with shape (3, 3, 128, 256)\n",
      "Saved block3_conv1_bias_0 with shape (256,)\n",
      "Saved block3_conv2_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved block3_conv2_bias_0 with shape (256,)\n",
      "Saved block3_conv3_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved block3_conv3_bias_0 with shape (256,)\n",
      "Saved block3_conv4_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved block3_conv4_bias_0 with shape (256,)\n",
      "Saved block4_conv1_kernel_0 with shape (3, 3, 256, 512)\n",
      "Saved block4_conv1_bias_0 with shape (512,)\n",
      "Saved block4_conv2_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved block4_conv2_bias_0 with shape (512,)\n",
      "Saved block4_conv3_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved block4_conv3_bias_0 with shape (512,)\n",
      "Saved block4_conv4_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved block4_conv4_bias_0 with shape (512,)\n",
      "Saved block5_conv1_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved block5_conv1_bias_0 with shape (512,)\n",
      "Saved block5_conv2_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved block5_conv2_bias_0 with shape (512,)\n",
      "\n",
      "Defining PyTorch model...\n",
      "\n",
      "Loading weights into PyTorch model...\n",
      "Loaded weights for conv1_1.weight\n",
      "Loaded weights for conv1_1.bias\n",
      "Loaded weights for conv1_2.weight\n",
      "Loaded weights for conv1_2.bias\n",
      "Loaded weights for conv2_1.weight\n",
      "Loaded weights for conv2_1.bias\n",
      "Loaded weights for conv2_2.weight\n",
      "Loaded weights for conv2_2.bias\n",
      "Loaded weights for conv3_1.weight\n",
      "Loaded weights for conv3_1.bias\n",
      "Loaded weights for conv3_2.weight\n",
      "Loaded weights for conv3_2.bias\n",
      "Loaded weights for conv3_3.weight\n",
      "Loaded weights for conv3_3.bias\n",
      "Loaded weights for conv4_1.weight\n",
      "Loaded weights for conv4_1.bias\n",
      "Loaded weights for conv4_2.weight\n",
      "Loaded weights for conv4_2.bias\n",
      "Loaded weights for conv4_3.weight\n",
      "Loaded weights for conv4_3.bias\n",
      "Loaded weights for conv5_1.weight\n",
      "Loaded weights for conv5_1.bias\n",
      "\n",
      "Conversion complete!\n",
      "\n",
      "Saving PyTorch model state dictionary...\n",
      "Model weights saved to ./models/enc_r51_updated.pth\n",
      "\n",
      "Verifying the output...\n",
      "Output shape: torch.Size([1, 512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Load TensorFlow Model and Extract Weights\n",
    "print(\"Loading TensorFlow model...\")\n",
    "model_path = '/home/sunayana/Documents/LinearStyleTransfer/models/vgg_r51/tensorflow-encoder-v1'\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "\n",
    "# Directory to save numpy weights\n",
    "weights_dir = \"./weights/enc_r51\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "print(\"Extracting and saving weights...\")\n",
    "# Extract weights from the TensorFlow model and save as .npy files\n",
    "for var in loaded_model.variables:\n",
    "    weight_name = var.name.replace(\"/\", \"_\").replace(\":\", \"_\")  # Clean up variable names\n",
    "    np.save(os.path.join(weights_dir, f\"{weight_name}.npy\"), var.numpy())\n",
    "    print(f\"Saved {weight_name} with shape {var.shape}\")\n",
    "\n",
    "# Step 2: Define the Equivalent PyTorch Model for Encoder r51\n",
    "print(\"\\nDefining PyTorch model...\")\n",
    "\n",
    "class VGGEncoderR51(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGEncoderR51, self).__init__()\n",
    "        # Defining encoder layers equivalent to TensorFlow model\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.maxPool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.maxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.maxPool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.relu1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.relu1_2(x)\n",
    "        x = self.maxPool1(x)\n",
    "\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.relu2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.relu2_2(x)\n",
    "        x = self.maxPool2(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.relu3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.relu3_2(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.relu3_3(x)\n",
    "        x = self.maxPool3(x)\n",
    "\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.relu4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.relu4_2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.relu4_3(x)\n",
    "        x = self.maxPool4(x)\n",
    "\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.relu5_1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize the PyTorch model\n",
    "torch_model = VGGEncoderR51()\n",
    "\n",
    "# Step 3: Load Weights from NumPy Files into PyTorch Model\n",
    "print(\"\\nLoading weights into PyTorch model...\")\n",
    "\n",
    "def load_weights(torch_model, weights_dir):\n",
    "    # Mapping of weight files to model parameter names\n",
    "    weight_files = {\n",
    "        \"conv1_1.weight\": \"block1_conv1_kernel_0.npy\",\n",
    "        \"conv1_1.bias\": \"block1_conv1_bias_0.npy\",\n",
    "        \"conv1_2.weight\": \"block1_conv2_kernel_0.npy\",\n",
    "        \"conv1_2.bias\": \"block1_conv2_bias_0.npy\",\n",
    "        \"conv2_1.weight\": \"block2_conv1_kernel_0.npy\",\n",
    "        \"conv2_1.bias\": \"block2_conv1_bias_0.npy\",\n",
    "        \"conv2_2.weight\": \"block2_conv2_kernel_0.npy\",\n",
    "        \"conv2_2.bias\": \"block2_conv2_bias_0.npy\",\n",
    "        \"conv3_1.weight\": \"block3_conv1_kernel_0.npy\",\n",
    "        \"conv3_1.bias\": \"block3_conv1_bias_0.npy\",\n",
    "        \"conv3_2.weight\": \"block3_conv2_kernel_0.npy\",\n",
    "        \"conv3_2.bias\": \"block3_conv2_bias_0.npy\",\n",
    "        \"conv3_3.weight\": \"block3_conv3_kernel_0.npy\",\n",
    "        \"conv3_3.bias\": \"block3_conv3_bias_0.npy\",\n",
    "        \"conv4_1.weight\": \"block4_conv1_kernel_0.npy\",\n",
    "        \"conv4_1.bias\": \"block4_conv1_bias_0.npy\",\n",
    "        \"conv4_2.weight\": \"block4_conv2_kernel_0.npy\",\n",
    "        \"conv4_2.bias\": \"block4_conv2_bias_0.npy\",\n",
    "        \"conv4_3.weight\": \"block4_conv3_kernel_0.npy\",\n",
    "        \"conv4_3.bias\": \"block4_conv3_bias_0.npy\",\n",
    "        \"conv5_1.weight\": \"block5_conv1_kernel_0.npy\",\n",
    "        \"conv5_1.bias\": \"block5_conv1_bias_0.npy\"\n",
    "    }\n",
    "\n",
    "    # Load weights into PyTorch model\n",
    "    for param_name, npy_file in weight_files.items():\n",
    "        # Get parameter tensor from model\n",
    "        param = getattr(torch_model, param_name.split(\".\")[0])\n",
    "        param_weight = torch.from_numpy(np.load(os.path.join(weights_dir, npy_file)))\n",
    "\n",
    "        # Transpose weights if it's a convolutional weight\n",
    "        if 'weight' in param_name:\n",
    "            param_weight = param_weight.permute(3, 2, 0, 1)  # (H, W, in_channels, out_channels) -> (out_channels, in_channels, H, W)\n",
    "\n",
    "        # Assign the weights to the PyTorch layer\n",
    "        if 'weight' in param_name:\n",
    "            param.weight.data.copy_(param_weight)\n",
    "        elif 'bias' in param_name:\n",
    "            param.bias.data.copy_(param_weight)\n",
    "        \n",
    "        print(f\"Loaded weights for {param_name}\")\n",
    "\n",
    "# Load weights into the PyTorch model\n",
    "load_weights(torch_model, weights_dir)\n",
    "\n",
    "print(\"\\nConversion complete!\")\n",
    "\n",
    "# Step 4: Save the PyTorch Model State Dictionary\n",
    "print(\"\\nSaving PyTorch model state dictionary...\")\n",
    "\n",
    "output_path = \"./models/enc_r51_updated.pth\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "torch.save(torch_model.state_dict(), output_path)\n",
    "print(f\"Model weights saved to {output_path}\")\n",
    "\n",
    "# Optional: Verify the output\n",
    "print(\"\\nVerifying the output...\")\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # Example input\n",
    "output = torch_model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorFlow model...\n",
      "Extracting and saving weights...\n",
      "Saved rev_block5_conv2_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved rev_block5_conv2_bias_0 with shape (512,)\n",
      "Saved rev_block5_conv1_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved rev_block5_conv1_bias_0 with shape (512,)\n",
      "Saved rev_block4_conv4_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved rev_block4_conv4_bias_0 with shape (512,)\n",
      "Saved rev_block4_conv3_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved rev_block4_conv3_bias_0 with shape (512,)\n",
      "Saved rev_block4_conv2_kernel_0 with shape (3, 3, 512, 512)\n",
      "Saved rev_block4_conv2_bias_0 with shape (512,)\n",
      "Saved rev_block4_conv1_kernel_0 with shape (3, 3, 512, 256)\n",
      "Saved rev_block4_conv1_bias_0 with shape (256,)\n",
      "Saved rev_block3_conv4_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved rev_block3_conv4_bias_0 with shape (256,)\n",
      "Saved rev_block3_conv3_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved rev_block3_conv3_bias_0 with shape (256,)\n",
      "Saved rev_block3_conv2_kernel_0 with shape (3, 3, 256, 256)\n",
      "Saved rev_block3_conv2_bias_0 with shape (256,)\n",
      "Saved rev_block3_conv1_kernel_0 with shape (3, 3, 256, 128)\n",
      "Saved rev_block3_conv1_bias_0 with shape (128,)\n",
      "Saved rev_block2_conv2_kernel_0 with shape (3, 3, 128, 128)\n",
      "Saved rev_block2_conv2_bias_0 with shape (128,)\n",
      "Saved rev_block2_conv1_kernel_0 with shape (3, 3, 128, 64)\n",
      "Saved rev_block2_conv1_bias_0 with shape (64,)\n",
      "Saved rev_block1_conv2_kernel_0 with shape (3, 3, 64, 64)\n",
      "Saved rev_block1_conv2_bias_0 with shape (64,)\n",
      "Saved rev_block1_conv1_kernel_0 with shape (3, 3, 64, 3)\n",
      "Saved rev_block1_conv1_bias_0 with shape (3,)\n",
      "\n",
      "Defining PyTorch model...\n",
      "\n",
      "Loading weights into PyTorch model...\n",
      "Loaded weights for conv15.weight\n",
      "Loaded weights for conv15.bias\n",
      "Loaded weights for conv16.weight\n",
      "Loaded weights for conv16.bias\n",
      "Loaded weights for conv17.weight\n",
      "Loaded weights for conv17.bias\n",
      "Skipping conv18.weight due to shape mismatch: torch.Size([512, 512, 3, 3]) vs torch.Size([256, 512, 3, 3])\n",
      "Loaded weights for conv18.weight\n",
      "Skipping conv18.bias due to shape mismatch: torch.Size([512]) vs torch.Size([256])\n",
      "Loaded weights for conv18.bias\n",
      "Skipping conv19.weight due to shape mismatch: torch.Size([256, 512, 3, 3]) vs torch.Size([256, 256, 3, 3])\n",
      "Loaded weights for conv19.weight\n",
      "Loaded weights for conv19.bias\n",
      "Loaded weights for conv20.weight\n",
      "Loaded weights for conv20.bias\n",
      "Skipping conv21.weight due to shape mismatch: torch.Size([256, 256, 3, 3]) vs torch.Size([128, 256, 3, 3])\n",
      "Loaded weights for conv21.weight\n",
      "Skipping conv21.bias due to shape mismatch: torch.Size([256]) vs torch.Size([128])\n",
      "Loaded weights for conv21.bias\n",
      "Skipping conv23.weight due to shape mismatch: torch.Size([128, 256, 3, 3]) vs torch.Size([128, 128, 3, 3])\n",
      "Loaded weights for conv23.weight\n",
      "Loaded weights for conv23.bias\n",
      "Skipping conv24.weight due to shape mismatch: torch.Size([128, 128, 3, 3]) vs torch.Size([64, 128, 3, 3])\n",
      "Loaded weights for conv24.weight\n",
      "Skipping conv24.bias due to shape mismatch: torch.Size([128]) vs torch.Size([64])\n",
      "Loaded weights for conv24.bias\n",
      "Skipping conv25.weight due to shape mismatch: torch.Size([64, 128, 3, 3]) vs torch.Size([64, 64, 3, 3])\n",
      "Loaded weights for conv25.weight\n",
      "Loaded weights for conv25.bias\n",
      "Skipping conv26.weight due to shape mismatch: torch.Size([64, 64, 3, 3]) vs torch.Size([3, 64, 3, 3])\n",
      "Loaded weights for conv26.weight\n",
      "Skipping conv26.bias due to shape mismatch: torch.Size([64]) vs torch.Size([3])\n",
      "Loaded weights for conv26.bias\n",
      "\n",
      "Saving model state dictionary...\n",
      "Model weights saved to models/dec_r51.pth\n",
      "\n",
      "Verifying the output...\n",
      "Output shape: torch.Size([1, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Load TensorFlow Model and Extract Weights\n",
    "print(\"Loading TensorFlow model...\")\n",
    "model_path = '/home/sunayana/Documents/LinearStyleTransfer/models/vgg_r51/tensorflow-decoder-v1'\n",
    "loaded_model = tf.saved_model.load(model_path)\n",
    "\n",
    "# Directory to save numpy weights\n",
    "weights_dir = \"./weights/dec_r51\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "print(\"Extracting and saving weights...\")\n",
    "# Extract weights from the TensorFlow model and save as .npy files\n",
    "for var in loaded_model.variables:\n",
    "    weight_name = var.name.replace(\"/\", \"_\").replace(\":\", \"_\")  # Clean up variable names\n",
    "    np.save(os.path.join(weights_dir, f\"{weight_name}.npy\"), var.numpy())\n",
    "    print(f\"Saved {weight_name} with shape {var.shape}\")\n",
    "\n",
    "# Step 2: Define the Equivalent PyTorch Model for Decoder r51\n",
    "print(\"\\nDefining PyTorch model...\")\n",
    "\n",
    "class VGGDecoderR51(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGDecoderR51, self).__init__()\n",
    "        # Defining decoder layers equivalent to TensorFlow model\n",
    "        self.reflecPad15 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv15 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu15 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "        self.reflecPad16 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv16 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu16 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad17 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv17 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu17 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad18 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv18 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu18 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad19 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv19 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu19 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "        self.reflecPad20 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv20 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu20 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad21 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv21 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu21 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad22 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv22 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu22 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad23 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv23 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu23 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "        self.reflecPad24 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv24 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu24 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad25 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv25 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu25 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.unpool4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "\n",
    "        self.reflecPad26 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv26 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu26 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.reflecPad27 = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.conv27 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reflecPad15(x)\n",
    "        x = self.conv15(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.unpool(x)\n",
    "\n",
    "        x = self.reflecPad16(x)\n",
    "        x = self.conv16(x)\n",
    "        x = self.relu16(x)\n",
    "\n",
    "        x = self.reflecPad17(x)\n",
    "        x = self.conv17(x)\n",
    "        x = self.relu17(x)\n",
    "\n",
    "        x = self.reflecPad18(x)\n",
    "        x = self.conv18(x)\n",
    "        x = self.relu18(x)\n",
    "\n",
    "        x = self.reflecPad19(x)\n",
    "        x = self.conv19(x)\n",
    "        x = self.relu19(x)\n",
    "        x = self.unpool2(x)\n",
    "\n",
    "        x = self.reflecPad20(x)\n",
    "        x = self.conv20(x)\n",
    "        x = self.relu20(x)\n",
    "\n",
    "        x = self.reflecPad21(x)\n",
    "        x = self.conv21(x)\n",
    "        x = self.relu21(x)\n",
    "\n",
    "        x = self.reflecPad22(x)\n",
    "        x = self.conv22(x)\n",
    "        x = self.relu22(x)\n",
    "\n",
    "        x = self.reflecPad23(x)\n",
    "        x = self.conv23(x)\n",
    "        x = self.relu23(x)\n",
    "        x = self.unpool3(x)\n",
    "\n",
    "        x = self.reflecPad24(x)\n",
    "        x = self.conv24(x)\n",
    "        x = self.relu24(x)\n",
    "\n",
    "        x = self.reflecPad25(x)\n",
    "        x = self.conv25(x)\n",
    "        x = self.relu25(x)\n",
    "        x = self.unpool4(x)\n",
    "\n",
    "        x = self.reflecPad26(x)\n",
    "        x = self.conv26(x)\n",
    "        x = self.relu26(x)\n",
    "\n",
    "        x = self.reflecPad27(x)\n",
    "        x = self.conv27(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize the PyTorch model\n",
    "torch_model = VGGDecoderR51()\n",
    "\n",
    "# Step 3: Load Weights from NumPy Files into PyTorch Model\n",
    "print(\"\\nLoading weights into PyTorch model...\")\n",
    "\n",
    "def load_weights(torch_model, weights_dir):\n",
    "    # Mapping of weight files to model parameter names\n",
    "    weight_files = {\n",
    "        \"conv15.weight\": \"rev_block5_conv1_kernel_0.npy\",\n",
    "        \"conv15.bias\": \"rev_block5_conv1_bias_0.npy\",\n",
    "        \"conv16.weight\": \"rev_block4_conv3_kernel_0.npy\",\n",
    "        \"conv16.bias\": \"rev_block4_conv3_bias_0.npy\",\n",
    "        \"conv17.weight\": \"rev_block4_conv2_kernel_0.npy\",\n",
    "        \"conv17.bias\": \"rev_block4_conv2_bias_0.npy\",\n",
    "        \"conv18.weight\": \"rev_block4_conv1_kernel_0.npy\",\n",
    "        \"conv18.bias\": \"rev_block4_conv1_bias_0.npy\",\n",
    "        \"conv19.weight\": \"rev_block3_conv3_kernel_0.npy\",\n",
    "        \"conv19.bias\": \"rev_block3_conv3_bias_0.npy\",\n",
    "        \"conv20.weight\": \"rev_block3_conv2_kernel_0.npy\",\n",
    "        \"conv20.bias\": \"rev_block3_conv2_bias_0.npy\",\n",
    "        \"conv21.weight\": \"rev_block3_conv1_kernel_0.npy\",\n",
    "        \"conv21.bias\": \"rev_block3_conv1_bias_0.npy\",\n",
    "        \"conv23.weight\": \"rev_block2_conv2_kernel_0.npy\",\n",
    "        \"conv23.bias\": \"rev_block2_conv2_bias_0.npy\",\n",
    "        \"conv24.weight\": \"rev_block2_conv1_kernel_0.npy\",\n",
    "        \"conv24.bias\": \"rev_block2_conv1_bias_0.npy\",\n",
    "        \"conv25.weight\": \"rev_block1_conv2_kernel_0.npy\",\n",
    "        \"conv25.bias\": \"rev_block1_conv2_bias_0.npy\",\n",
    "        \"conv26.weight\": \"rev_block1_conv1_kernel_0.npy\",\n",
    "        \"conv26.bias\": \"rev_block1_conv1_bias_0.npy\"\n",
    "    }\n",
    "\n",
    "    # Load weights into the PyTorch model\n",
    "    for param_name, npy_file in weight_files.items():\n",
    "        # Get parameter tensor from model\n",
    "        param = getattr(torch_model, param_name.split(\".\")[0])\n",
    "        param_weight = torch.from_numpy(np.load(os.path.join(weights_dir, npy_file)))\n",
    "\n",
    "        # Transpose weights if it's a convolutional weight\n",
    "        if 'weight' in param_name and len(param_weight.shape) == 4:\n",
    "            param_weight = param_weight.permute(3, 2, 0, 1)\n",
    "\n",
    "        # Assign weights to model\n",
    "        if 'weight' in param_name:\n",
    "            if param.weight.data.shape == param_weight.shape:\n",
    "                param.weight.data.copy_(param_weight)\n",
    "            else:\n",
    "                print(f\"Skipping {param_name} due to shape mismatch: {param.weight.data.shape} vs {param_weight.shape}\")\n",
    "        elif 'bias' in param_name:\n",
    "            if param.bias.data.shape == param_weight.shape:\n",
    "                param.bias.data.copy_(param_weight)\n",
    "            else:\n",
    "                print(f\"Skipping {param_name} due to shape mismatch: {param.bias.data.shape} vs {param_weight.shape}\")\n",
    "\n",
    "        print(f\"Loaded weights for {param_name}\")\n",
    "\n",
    "load_weights(torch_model, weights_dir)\n",
    "\n",
    "# Step 4: Save the Model as .pth File\n",
    "print(\"\\nSaving model state dictionary...\")\n",
    "output_path = \"models/dec_r51.pth\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "torch.save(torch_model.state_dict(), output_path)\n",
    "\n",
    "print(f\"Model weights saved to {output_path}\")\n",
    "\n",
    "# Optional: Verify the output\n",
    "print(\"\\nVerifying the output...\")\n",
    "input_tensor = torch.randn(1, 512, 7, 7)  # Input tensor for testing (match the expected input shape)\n",
    "output = torch_model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys in the renamed state dictionary do not match the model's state dictionary.\n",
      "Renamed state keys: dict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias'])\n",
      "Model state keys: odict_keys(['conv1.weight', 'conv1.bias'])\n",
      "Parameter conv1.weight matches in shape: torch.Size([64, 3, 3, 3])\n",
      "Parameter conv1.bias matches in shape: torch.Size([64])\n",
      "Error loading model weights: Error(s) in loading state_dict for EncoderR11:\n",
      "\tUnexpected key(s) in state_dict: \"conv2.weight\", \"conv2.bias\". \n",
      "Verification Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278137/79259891.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(saved_state_dict_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the encoder or decoder models based on your model definition\n",
    "class EncoderR11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderR11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        return x\n",
    "\n",
    "# Define the model for which you want to verify the state dictionary\n",
    "def create_model(layer_name):\n",
    "    if layer_name == \"encoder_r11\":\n",
    "        return EncoderR11()\n",
    "    # Add other encoder and decoder class definitions as needed\n",
    "    # (Example, EncoderR21, DecoderR11, etc.)\n",
    "    # Example: return EncoderR21() for `encoder_r21`\n",
    "\n",
    "# Load the saved state dictionary from file\n",
    "saved_state_dict_path = 'models/vgg_r11.pth'  # Replace with the actual path\n",
    "saved_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "# Initialize the model\n",
    "layer_name = 'encoder_r11'  # Replace with the specific layer you want to check\n",
    "model = create_model(layer_name)\n",
    "\n",
    "# Get the state dictionary of the model\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Rename keys in saved state dictionary to match the model state dictionary keys\n",
    "renamed_state_dict = {}\n",
    "for key in saved_state_dict.keys():\n",
    "    if key.startswith(\"conv1_1\"):\n",
    "        new_key = key.replace(\"conv1_1\", \"conv1\")  # Rename 'conv1_1' to 'conv1' to match model key\n",
    "    elif key.startswith(\"conv1_2\"):\n",
    "        new_key = key.replace(\"conv1_2\", \"conv2\")  # Adjust if other layers are present\n",
    "    else:\n",
    "        new_key = key  # If no change is required, use the original key\n",
    "\n",
    "    renamed_state_dict[new_key] = saved_state_dict[key]\n",
    "\n",
    "# Verify if all keys match after renaming\n",
    "if renamed_state_dict.keys() != model_state_dict.keys():\n",
    "    print(\"The keys in the renamed state dictionary do not match the model's state dictionary.\")\n",
    "    print(\"Renamed state keys:\", renamed_state_dict.keys())\n",
    "    print(\"Model state keys:\", model_state_dict.keys())\n",
    "else:\n",
    "    print(\"The keys in the renamed state dictionary match the model's state dictionary.\")\n",
    "\n",
    "# Check if the shapes of each parameter match after renaming\n",
    "for key in model_state_dict.keys():\n",
    "    if key in renamed_state_dict:\n",
    "        saved_shape = renamed_state_dict[key].shape\n",
    "        model_shape = model_state_dict[key].shape\n",
    "        if saved_shape != model_shape:\n",
    "            print(f\"Mismatch found in key: {key}\")\n",
    "            print(f\"Saved state shape: {saved_shape}, Model state shape: {model_shape}\")\n",
    "        else:\n",
    "            print(f\"Parameter {key} matches in shape: {saved_shape}\")\n",
    "    else:\n",
    "        print(f\"Key {key} not found in renamed state dictionary.\")\n",
    "\n",
    "# Load the renamed state dict into the model\n",
    "try:\n",
    "    model.load_state_dict(renamed_state_dict)\n",
    "    print(\"Model weights successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {e}\")\n",
    "\n",
    "print(\"Verification Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully.\n",
      "Updated model state dictionary saved to 'updated_model_r11.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278137/4068817227.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(saved_state_dict_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the saved state dictionary from the .pth file\n",
    "saved_state_dict_path = 'models/vgg_r11.pth'  # Replace with the correct path\n",
    "saved_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "# Define a function to rename keys in the saved state dictionary to match the model's keys\n",
    "def rename_keys(saved_state_dict):\n",
    "    new_state_dict = {}\n",
    "    for key in saved_state_dict.keys():\n",
    "        if 'conv1_1' in key:\n",
    "            new_key = key.replace('conv1_1', 'conv1')  # Rename to match model definition\n",
    "        elif 'conv1_2' in key:\n",
    "            new_key = key.replace('conv1_2', 'conv2')  # Update the conv layer name accordingly\n",
    "        else:\n",
    "            new_key = key  # If the key does not need renaming, leave it as it is\n",
    "        new_state_dict[new_key] = saved_state_dict[key]\n",
    "    return new_state_dict\n",
    "\n",
    "# Rename keys in the saved state dictionary\n",
    "renamed_state_dict = rename_keys(saved_state_dict)\n",
    "\n",
    "# Define the model to load the weights into\n",
    "class EncoderR11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderR11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = EncoderR11()\n",
    "\n",
    "# Load the renamed state dictionary into the model\n",
    "model.load_state_dict(renamed_state_dict)\n",
    "\n",
    "# Confirm that the weights have been loaded correctly\n",
    "print(\"Model weights loaded successfully.\")\n",
    "\n",
    "# Optional: Save the updated model with renamed keys for future use\n",
    "torch.save(model.state_dict(), 'updated_model_r11.pth')\n",
    "print(\"Updated model state dictionary saved to 'updated_model_r11.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading weights: Error(s) in loading state_dict for EncoderR21:\n",
      "\tMissing key(s) in state_dict: \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1_1.weight\", \"conv1_1.bias\", \"conv1_2.weight\", \"conv1_2.bias\". \n",
      "\tsize mismatch for conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n",
      "\tsize mismatch for conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "Updated model state dictionary saved to 'updated_model_r21.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278137/623198150.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(saved_state_dict_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the saved state dictionary from the .pth file\n",
    "saved_state_dict_path = 'models/vgg_r21.pth'  # Replace with the correct path\n",
    "saved_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "# Define a function to rename keys in the saved state dictionary to match the model's keys\n",
    "def rename_keys(saved_state_dict):\n",
    "    new_state_dict = {}\n",
    "    for key in saved_state_dict.keys():\n",
    "        if 'conv2_1' in key:\n",
    "            new_key = key.replace('conv2_1', 'conv1')  # Rename to match model definition for layer 1\n",
    "        elif 'conv2_2' in key:\n",
    "            new_key = key.replace('conv2_2', 'conv2')  # Rename to match model definition for layer 2\n",
    "        else:\n",
    "            new_key = key  # If the key does not need renaming, leave it as it is\n",
    "        new_state_dict[new_key] = saved_state_dict[key]\n",
    "    return new_state_dict\n",
    "\n",
    "# Rename keys in the saved state dictionary\n",
    "renamed_state_dict = rename_keys(saved_state_dict)\n",
    "\n",
    "# Define the model to load the weights into\n",
    "class EncoderR21(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderR21, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = EncoderR21()\n",
    "\n",
    "# Load the renamed state dictionary into the model\n",
    "try:\n",
    "    model.load_state_dict(renamed_state_dict)\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "\n",
    "# Optional: Save the updated model with renamed keys for future use\n",
    "torch.save(model.state_dict(), 'updated_model_r21.pth')\n",
    "print(\"Updated model state dictionary saved to 'updated_model_r21.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights for conv1.weight\n",
      "Loaded weights for conv1.bias\n",
      "Size mismatch for conv2.weight: expected torch.Size([128, 64, 3, 3]), got torch.Size([64, 64, 3, 3])\n",
      "Size mismatch for conv2.bias: expected torch.Size([128]), got torch.Size([64])\n",
      "Size mismatch for conv3.weight: expected torch.Size([256, 128, 3, 3]), got torch.Size([128, 64, 3, 3])\n",
      "Size mismatch for conv3.bias: expected torch.Size([256]), got torch.Size([128])\n",
      "Updated model state dictionary saved to 'updated_model_r21.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278137/4235575760.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(saved_state_dict_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the saved state dictionary from the .pth file\n",
    "saved_state_dict_path = 'models/vgg_r21.pth'  # Replace with the correct path\n",
    "saved_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "# Define a function to rename keys in the saved state dictionary to match the model's keys\n",
    "def rename_keys(saved_state_dict):\n",
    "    new_state_dict = {}\n",
    "    for key in saved_state_dict.keys():\n",
    "        if 'conv1_1' in key:\n",
    "            new_key = key.replace('conv1_1', 'conv1')  # Rename to match model definition for layer 1\n",
    "        elif 'conv1_2' in key:\n",
    "            new_key = key.replace('conv1_2', 'conv2')  # Rename to match model definition for layer 2\n",
    "        elif 'conv2_1' in key:\n",
    "            new_key = key.replace('conv2_1', 'conv3')  # Rename to match model definition for layer 3\n",
    "        else:\n",
    "            new_key = key  # If the key does not need renaming, leave it as it is\n",
    "        new_state_dict[new_key] = saved_state_dict[key]\n",
    "    return new_state_dict\n",
    "\n",
    "# Rename keys in the saved state dictionary\n",
    "renamed_state_dict = rename_keys(saved_state_dict)\n",
    "\n",
    "# Define the EncoderR21 Model\n",
    "class EncoderR21(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderR21, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=1)  # Adjusted for matching the size of loaded weights\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = EncoderR21()\n",
    "\n",
    "# Handle Size Mismatch Manually\n",
    "for name, param in model.named_parameters():\n",
    "    if name in renamed_state_dict:\n",
    "        saved_param = renamed_state_dict[name]\n",
    "        if param.size() == saved_param.size():\n",
    "            param.data.copy_(saved_param)\n",
    "            print(f\"Loaded weights for {name}\")\n",
    "        else:\n",
    "            print(f\"Size mismatch for {name}: expected {param.size()}, got {saved_param.size()}\")\n",
    "\n",
    "# Optional: Save the updated model with renamed keys for future use\n",
    "torch.save(model.state_dict(), 'updated_model_r21.pth')\n",
    "print(\"Updated model state dictionary saved to 'updated_model_r21.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys in the filtered state dictionary match the model's state dictionary.\n",
      "Parameter conv1.weight matches in shape: torch.Size([64, 3, 3, 3])\n",
      "Parameter conv1.bias matches in shape: torch.Size([64])\n",
      "Model weights successfully loaded.\n",
      "Verification Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_298324/2868298935.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(saved_state_dict_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the encoder or decoder models based on your model definition\n",
    "class EncoderR11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderR11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        return x\n",
    "\n",
    "# Define the model for which you want to verify and update the state dictionary\n",
    "def create_model(layer_name):\n",
    "    if layer_name == \"encoder_r11\":\n",
    "        return EncoderR11()\n",
    "    # Add other encoder and decoder class definitions as needed\n",
    "    return None\n",
    "\n",
    "# Load the saved state dictionary from file\n",
    "saved_state_dict_path = 'models/vgg_r11.pth'  # Replace with the actual path\n",
    "saved_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "# Initialize the model\n",
    "layer_name = 'encoder_r11'  # Replace with the specific layer you want to check\n",
    "model = create_model(layer_name)\n",
    "\n",
    "# Rename keys in the saved state dictionary to match the model's state dictionary keys\n",
    "renamed_state_dict = {}\n",
    "for key in saved_state_dict.keys():\n",
    "    if key.startswith(\"conv1_1\"):\n",
    "        new_key = key.replace(\"conv1_1\", \"conv1\")  # Rename 'conv1_1' to 'conv1' to match model key\n",
    "    elif key.startswith(\"conv1_2\"):\n",
    "        # Since `conv1_2` isn't present in `EncoderR11`, we will skip adding it.\n",
    "        continue\n",
    "    else:\n",
    "        new_key = key  # If no change is required, use the original key\n",
    "\n",
    "    renamed_state_dict[new_key] = saved_state_dict[key]\n",
    "\n",
    "# Filter out keys that do not exist in the model's state dictionary\n",
    "filtered_state_dict = {k: v for k, v in renamed_state_dict.items() if k in model.state_dict()}\n",
    "\n",
    "# Check if all keys match after renaming and filtering\n",
    "if filtered_state_dict.keys() != model.state_dict().keys():\n",
    "    print(\"The keys in the filtered state dictionary do not fully match the model's state dictionary.\")\n",
    "    print(\"Filtered state keys:\", filtered_state_dict.keys())\n",
    "    print(\"Model state keys:\", model.state_dict().keys())\n",
    "else:\n",
    "    print(\"The keys in the filtered state dictionary match the model's state dictionary.\")\n",
    "\n",
    "# Check if the shapes of each parameter match after filtering\n",
    "for key in filtered_state_dict.keys():\n",
    "    if key in model.state_dict():\n",
    "        saved_shape = filtered_state_dict[key].shape\n",
    "        model_shape = model.state_dict()[key].shape\n",
    "        if saved_shape != model_shape:\n",
    "            print(f\"Mismatch found in key: {key}\")\n",
    "            print(f\"Saved state shape: {saved_shape}, Model state shape: {model_shape}\")\n",
    "        else:\n",
    "            print(f\"Parameter {key} matches in shape: {saved_shape}\")\n",
    "\n",
    "# Load the filtered state dict into the model\n",
    "try:\n",
    "    model.load_state_dict(filtered_state_dict)\n",
    "    print(\"Model weights successfully loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {e}\")\n",
    "\n",
    "print(\"Verification Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state_dict = torch.load(saved_state_dict_path, weights_only=True)\n",
    "torch.save(model.state_dict(), 'updated_model_r11.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
