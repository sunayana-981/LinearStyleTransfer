{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from libs.models import encoder3,encoder4\n",
    "from libs.models import decoder3,decoder4\n",
    "import numpy as np\n",
    "from libs.Matrix import MulLayer\n",
    "from libs.Criterion import LossCriterion\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.Loader import Dataset\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LossCriterion(nn.Module):\n",
    "    def __init__(self, style_layers, content_layers, style_weight, content_weight):\n",
    "        super(LossCriterion, self).__init__()\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.style_weight = style_weight\n",
    "        self.content_weight = content_weight\n",
    "        self.styleLosses = [styleLoss()] * len(style_layers)\n",
    "        self.contentLosses = [nn.MSELoss()] * len(content_layers)\n",
    "\n",
    "    def forward(self, tF, sF, cF):\n",
    "        # Content loss\n",
    "        totalContentLoss = 0\n",
    "        for i, layer in enumerate(self.content_layers):\n",
    "            cf_i = cF[layer].detach()\n",
    "            tf_i = tF[layer]\n",
    "            loss_i = self.contentLosses[i]\n",
    "            totalContentLoss += loss_i(tf_i, cf_i)\n",
    "        totalContentLoss = totalContentLoss * self.content_weight\n",
    "\n",
    "        # Style loss\n",
    "        \n",
    "        totalStyleLoss = 0\n",
    "        for i, layer in enumerate(self.style_layers):\n",
    "            sf_i = sF[layer].detach()\n",
    "            tf_i = tF[layer]\n",
    "            loss_i = self.styleLosses[i]\n",
    "            totalStyleLoss += loss_i(tf_i, sf_i)\n",
    "        totalStyleLoss = totalStyleLoss * self.style_weight\n",
    "\n",
    "        loss = totalStyleLoss + totalContentLoss\n",
    "        return loss, totalStyleLoss, totalContentLoss\n",
    "\n",
    "\n",
    "class styleLoss(nn.Module):\n",
    "    def forward(self,input,target):\n",
    "        ib,ic,ih,iw = input.size()\n",
    "        iF = input.view(ib,ic,-1)\n",
    "        iMean = torch.mean(iF,dim=2)\n",
    "        iCov = GramMatrix()(input)\n",
    "\n",
    "        tb,tc,th,tw = target.size()\n",
    "        tF = target.view(tb,tc,-1)\n",
    "        tMean = torch.mean(tF,dim=2)\n",
    "        tCov = GramMatrix()(target)\n",
    "\n",
    "        loss = nn.MSELoss(size_average=False)(iMean,tMean) + nn.MSELoss(size_average=False)(iCov,tCov)\n",
    "        return loss/tb\n",
    "\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self,input):\n",
    "        b, c, h, w = input.size()\n",
    "        f = input.view(b,c,h*w) # bxcx(hxw)\n",
    "        # torch.bmm(batch1, batch2, out=None)   #\n",
    "        # batch1: bxmxp, batch2: bxpxn -> bxmxn #\n",
    "        G = torch.bmm(f,f.transpose(1,2)) # f: bxcx(hxw), f.transpose: bx(hxw)xc -> bxcxc\n",
    "        return G.div_(c*h*w)\n",
    "\n",
    "class LossSensitivity:\n",
    "    def __init__(self, vgg: nn.Module, dec: nn.Module, matrix: MulLayer,\n",
    "                 style_layers: List[str], content_layers: List[str],\n",
    "                 style_weight: float, content_weight: float, device: torch.device):\n",
    "        self.vgg = vgg.to(device)\n",
    "        self.dec = dec.to(device)\n",
    "        self.matrix = matrix.to(device)\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.criterion = LossCriterion(style_layers, content_layers, style_weight, content_weight)\n",
    "        self.device = device\n",
    "\n",
    "    def add_noise(self, matrix: torch.Tensor, sigma: float) -> torch.Tensor:\n",
    "        \"\"\"Adds random Gaussian noise to a matrix.\"\"\"\n",
    "        return matrix + torch.randn_like(matrix) * sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, contentV: torch.Tensor, styleV: torch.Tensor) -> Tuple[dict, dict]:\n",
    "        return self.vgg(styleV), self.vgg(contentV)\n",
    "\n",
    "    def compute_loss(self, contentV: torch.Tensor, styleV: torch.Tensor, noisy_matrix: torch.Tensor) -> float:\n",
    "        sF, cF = self.forward(contentV, styleV)\n",
    "\n",
    "        transformed_features, _ = self.matrix(cF[self.style_layers[0]], sF[self.style_layers[0]])\n",
    "        b, c, h, w = transformed_features.size()\n",
    "        compressed_features = self.matrix.compress(transformed_features)\n",
    "\n",
    "        if noisy_matrix.size(1) != compressed_features.view(b, self.matrix.matrixSize, -1).size(1):\n",
    "            print(f\"Dimension mismatch: {noisy_matrix.size()} vs {compressed_features.size()}\")\n",
    "            return float('inf')\n",
    "\n",
    "        noisy_transfeature = torch.bmm(noisy_matrix, compressed_features.view(b, self.matrix.matrixSize, -1))\n",
    "        noisy_transfeature = noisy_transfeature.view(b, self.matrix.matrixSize, h, w)\n",
    "        noisy_transfeature = self.matrix.unzip(noisy_transfeature)\n",
    "\n",
    "        noisy_transfer = self.dec(noisy_transfeature).clamp(0, 1)\n",
    "        tF = self.vgg(noisy_transfer)\n",
    "\n",
    "        total_loss, _, _ = self.criterion(tF, sF, cF)\n",
    "        return total_loss.item()\n",
    "\n",
    "    # def generate_stylized_image(self, contentV: torch.Tensor, styleV: torch.Tensor, noisy_matrix: torch.Tensor) -> torch.Tensor:\n",
    "    #     \"\"\"Generates the stylized image using the given noisy transformation matrix.\"\"\"\n",
    "    #     sF, cF = self.forward(contentV, styleV)\n",
    "\n",
    "    #     transformed_features, _ = self.matrix(cF[self.style_layers[0]], sF[self.style_layers[0]])\n",
    "    #     b, c, h, w = transformed_features.size()\n",
    "    #     compressed_features = self.matrix.compress(transformed_features)\n",
    "\n",
    "    #     noisy_transfeature = torch.bmm(noisy_matrix, compressed_features.view(b, self.matrix.matrixSize, -1))\n",
    "    #     noisy_transfeature = noisy_transfeature.view(b, self.matrix.matrixSize, h, w)\n",
    "    #     noisy_transfeature = self.matrix.unzip(noisy_transfeature)\n",
    "\n",
    "    #     noisy_transfer = self.dec(noisy_transfeature).clamp(0, 1)\n",
    "    #     return noisy_transfer\n",
    "\n",
    "    def run_experiment(self, contentV: torch.Tensor, styleV: torch.Tensor,\n",
    "                       sigmas: np.ndarray, matrix: torch.Tensor) -> List[float]:\n",
    "        \"\"\"Runs the experiment for different noise levels and computes loss for each.\"\"\"\n",
    "        loss_values = []\n",
    "\n",
    "        for sigma in sigmas:\n",
    "            noisy_matrix = self.add_noise(matrix, sigma)\n",
    "\n",
    "            loss = self.compute_loss(contentV, styleV, noisy_matrix)\n",
    "            if loss == float('inf'):\n",
    "                print(f\"Skipping sigma {sigma} due to dimension mismatch.\")\n",
    "                continue\n",
    "\n",
    "            loss_values.append(loss)  # Store only the loss related to random noise\n",
    "\n",
    "        return loss_values\n",
    "\n",
    "\n",
    "def process_style_dir(style_dir: str, opt, loss_sensitivity: LossSensitivity,\n",
    "                      sigmas: np.ndarray, device: torch.device) -> np.ndarray:\n",
    "    style_path = os.path.join(opt.matrixPath, style_dir)\n",
    "    matrix_files = [f for f in os.listdir(style_path) if f.endswith('.pth')]\n",
    "\n",
    "    total_loss_values = np.zeros(len(sigmas))\n",
    "    num_matrices = 0\n",
    "\n",
    "    content_dataset = Dataset(opt.contentPath, opt.loadSize, opt.fineSize)\n",
    "    style_dataset = Dataset(opt.stylePath, opt.loadSize, opt.fineSize)\n",
    "\n",
    "    # Loop over all matrices saved for this style\n",
    "    for matrix_file in tqdm(matrix_files, desc=f\"Processing {style_dir}\"):\n",
    "        matrix_path = os.path.join(style_path, matrix_file)\n",
    "        saved_matrix = torch.load(matrix_path, map_location=device)\n",
    "\n",
    "        num_content_images = 0\n",
    "        loss_values_accumulated = np.zeros(len(sigmas))\n",
    "\n",
    "        # Loop over all content images\n",
    "        for contentV, _ in content_dataset:\n",
    "            contentV = contentV.unsqueeze(0).to(device)\n",
    "            styleV = style_dataset[0][0].unsqueeze(0).to(device)\n",
    "\n",
    "            # Run experiment for this content image\n",
    "            loss_values = loss_sensitivity.run_experiment(contentV, styleV, sigmas, saved_matrix)\n",
    "\n",
    "            # Accumulate losses for each sigma\n",
    "            loss_values_accumulated += np.array(loss_values)\n",
    "            num_content_images += 1\n",
    "\n",
    "        # Average loss values for each content image and add to total losses\n",
    "        total_loss_values += loss_values_accumulated / num_content_images\n",
    "        num_matrices += 1\n",
    "\n",
    "    # Average the accumulated results over the number of style matrices\n",
    "    avg_loss_values = total_loss_values / num_matrices\n",
    "\n",
    "    return avg_loss_values\n",
    "\n",
    "\n",
    "\n",
    "def plot_style_results(style_dir: str, sigmas: np.ndarray, avg_loss_values: np.ndarray):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(sigmas, avg_loss_values, '-o')\n",
    "    plt.xlabel('Sigma (Noise Level)')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title(f'Loss Sensitivity for Style: {style_dir}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'noise_sensitivity_{style_dir}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_intermediate_images(intermediate_images: List[Tuple[float, torch.Tensor]], style_dir: str):\n",
    "    \"\"\"Plot intermediate stylized images for the given sigma levels.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    num_images = len(intermediate_images)\n",
    "\n",
    "    for idx, (sigma, image_tensor) in enumerate(intermediate_images):\n",
    "        plt.subplot(1, num_images, idx + 1)\n",
    "        image = image_tensor.squeeze().permute(1, 2, 0).numpy()\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Sigma = {sigma:.2f}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f'Stylized Images for Style: {style_dir}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'stylized_images_{style_dir}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_style_loss_trend_for_noise_level(style_dir: str, sigmas: np.ndarray, avg_loss_values: np.ndarray):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sigmas, avg_loss_values, '-o')\n",
    "    plt.xlabel('Sigma (Noise Level)')\n",
    "    plt.ylabel('Average Loss Across Content Images')\n",
    "    plt.title(f'Average Loss for Style: {style_dir}')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_models(device: torch.device) -> Tuple[nn.Module, nn.Module, MulLayer]:\n",
    "    vgg = encoder4()\n",
    "    dec = decoder4()\n",
    "    matrix = MulLayer('r41')\n",
    "    vgg.load_state_dict(torch.load('models/vgg_r41.pth', map_location=device))\n",
    "    dec.load_state_dict(torch.load('models/dec_r41.pth', map_location=device))\n",
    "    return vgg, dec, matrix\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.contentPath = \"data/content/\"\n",
    "        self.stylePath = \"data/style/\"\n",
    "        self.loadSize = 256\n",
    "        self.fineSize = 256\n",
    "        self.matrixPath = \"Matrices/\"\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load models\n",
    "    vgg, dec, matrix = load_models(device)\n",
    "\n",
    "    # Define options and parameters\n",
    "    opt = Options()\n",
    "    sigmas = np.linspace(0, 200, 100)  # Noise levels to test\n",
    "\n",
    "    # Initialize the loss sensitivity object with valid layer identifiers\n",
    "    loss_sensitivity = LossSensitivity(vgg, dec, matrix, style_layers=['r41'], content_layers=['r41'],\n",
    "                                       style_weight=1.0, content_weight=1.0, device=device)\n",
    "\n",
    "    # Loop over style directories\n",
    "    style_dirs = os.listdir(opt.matrixPath)\n",
    "\n",
    "    for style_dir in style_dirs:\n",
    "        # Process each style directory to get average loss values for each sigma\n",
    "        avg_loss_values = process_style_dir(style_dir, opt, loss_sensitivity, sigmas, device)\n",
    "\n",
    "        # Plot the trend of average loss across content images for this style\n",
    "        plot_style_loss_trend_for_noise_level(style_dir, sigmas, avg_loss_values)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
