{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.contentPath = \"data/content/\"\n",
    "        self.stylePath = \"data/style/\"\n",
    "        self.loadSize = 256\n",
    "        self.fineSize = 256\n",
    "        self.matrixPath = \"Matrices/\"\n",
    "        self.vgg_dir = 'models/vgg_r41.pth'\n",
    "        self.decoder_dir = 'models/dec_r41.pth'\n",
    "        self.layer = 'r41'\n",
    "        self.outf = \"Artistic/rotation/\"\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "        self.batchSize = 1\n",
    "        self.matrixPath = 'models/r41.pth'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import torchvision.transforms as transforms\n",
    "    from tqdm import tqdm\n",
    "    from libs.Loader import Dataset\n",
    "    from libs.Matrix import MulLayer\n",
    "    from libs.models import encoder3, encoder4, decoder3, decoder4\n",
    "    from libs.utils import print_options\n",
    "    import torch.backends.cudnn as cudnn\n",
    "\n",
    "    def rotate_matrix(matrix, theta_degrees):\n",
    "        \"\"\"\n",
    "        Directly rotate the transformation matrix using rotation in multiple dimensions\n",
    "        \"\"\"\n",
    "        # Convert to numpy for easier manipulation\n",
    "        matrix_np = matrix.cpu().numpy()\n",
    "        \n",
    "        # Get the shape\n",
    "        original_shape = matrix_np.shape\n",
    "        \n",
    "        # Convert angle to radians\n",
    "        theta = np.radians(theta_degrees)\n",
    "        \n",
    "        # Create rotation matrices for each pair of dimensions\n",
    "        rotated = matrix_np.copy()\n",
    "        \n",
    "        # Rotate in multiple planes (taking pairs of dimensions)\n",
    "        for i in range(original_shape[1] - 1):\n",
    "            for j in range(i + 1, original_shape[1]):\n",
    "                # Create rotation matrix for this plane\n",
    "                rot_matrix = np.eye(original_shape[1])\n",
    "                rot_matrix[i, i] = np.cos(theta)\n",
    "                rot_matrix[i, j] = -np.sin(theta)\n",
    "                rot_matrix[j, i] = np.sin(theta)\n",
    "                rot_matrix[j, j] = np.cos(theta)\n",
    "                \n",
    "                # Apply rotation\n",
    "                rotated = np.matmul(rotated, rot_matrix)\n",
    "        \n",
    "        # Convert back to tensor\n",
    "        return torch.tensor(rotated, device=matrix.device, dtype=matrix.dtype)\n",
    "\n",
    "    opt = Options()\n",
    "    print_options(opt)\n",
    "\n",
    "    os.makedirs(opt.outf, exist_ok=True)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    ################# MODEL #################\n",
    "    if opt.layer == 'r31':\n",
    "        vgg = encoder3()\n",
    "        dec = decoder3()\n",
    "    elif opt.layer == 'r41':\n",
    "        vgg = encoder4()\n",
    "        dec = decoder4()\n",
    "    matrix = MulLayer(opt.layer)\n",
    "    vgg.load_state_dict(torch.load(opt.vgg_dir))\n",
    "    dec.load_state_dict(torch.load(opt.decoder_dir))\n",
    "    matrix.load_state_dict(torch.load(opt.matrixPath))\n",
    "\n",
    "    ################# GPU #################\n",
    "    if opt.cuda:\n",
    "        vgg.cuda()\n",
    "        dec.cuda()\n",
    "        matrix.cuda()\n",
    "\n",
    "    content_files = [f for f in os.listdir(opt.contentPath) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    style_files = [f for f in os.listdir(opt.stylePath) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((opt.fineSize, opt.fineSize))\n",
    "    ])\n",
    "\n",
    "    # Define rotation angles\n",
    "    thetas = list(range(0, 10, 1))  # 0 to 180 degrees in steps of 30\n",
    "\n",
    "    # Add progress bar for the style loop\n",
    "    for style in tqdm(style_files, desc=\"Processing Styles\"):\n",
    "        style_image = Image.open(opt.stylePath + style).convert('RGB')\n",
    "        style_tensor = transform(style_image).unsqueeze(0)\n",
    "\n",
    "        # Add progress bar for the content loop\n",
    "        for content in tqdm(content_files, desc=\"Processing Contents\", leave=False):\n",
    "            content_image = Image.open(opt.contentPath + content).convert('RGB')\n",
    "            content_tensor = transform(content_image).unsqueeze(0)\n",
    "\n",
    "            contentV = torch.Tensor(1, 3, opt.fineSize, opt.fineSize).copy_(content_tensor)\n",
    "            styleV = torch.Tensor(1, 3, opt.fineSize, opt.fineSize).copy_(style_tensor)\n",
    "            \n",
    "            if opt.cuda:\n",
    "                contentV = contentV.cuda()\n",
    "                styleV = styleV.cuda()\n",
    "\n",
    "            ################# FORWARD PASS WITH ROTATION #################\n",
    "            images = []  # List to store the images with rotation\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sF = vgg(styleV)\n",
    "                cF = vgg(contentV)\n",
    "\n",
    "                # Get the original transformation matrix\n",
    "                if opt.layer == 'r41':\n",
    "                    feature, transmatrix = matrix(cF[opt.layer], sF[opt.layer], trans=True)\n",
    "                else:\n",
    "                    feature, transmatrix = matrix(cF, sF, trans=True)\n",
    "\n",
    "                compress_content = matrix.compress(cF[opt.layer] if opt.layer == 'r41' else cF)\n",
    "                b, c, h, w = compress_content.size()\n",
    "                compress_content = compress_content.view(b, c, -1)\n",
    "\n",
    "                # Process each rotation angle\n",
    "                for theta in thetas:\n",
    "                    # Print shape information for debugging\n",
    "                    #print(f\"Matrix shape before rotation: {transmatrix.shape}\")\n",
    "                    \n",
    "                    # Rotate the transformation matrix\n",
    "                    rotated_matrix = rotate_matrix(transmatrix, theta)\n",
    "                    \n",
    "                    # Apply the rotated matrix\n",
    "                    transfeature = torch.bmm(rotated_matrix, compress_content).view(b, matrix.matrixSize, h, w)\n",
    "                    out = matrix.unzip(transfeature)\n",
    "                    out = out + torch.mean(cF[opt.layer if opt.layer == 'r41' else cF], dim=(2, 3), keepdim=True)\n",
    "                    \n",
    "                    transfer_rotated = dec(out)\n",
    "                    transfer_rotated = transfer_rotated.clamp(0, 1)\n",
    "                    \n",
    "                    img_numpy = transfer_rotated.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "                    images.append(img_numpy)\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            # Plot the results\n",
    "            num_rows = 2\n",
    "            num_cols = len(thetas) // 2 + len(thetas) % 2\n",
    "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 8))\n",
    "            \n",
    "            for idx, ax in enumerate(axes.flatten()):\n",
    "                if idx < len(images):\n",
    "                    ax.imshow(images[idx])\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f'θ={thetas[idx]}°')\n",
    "                else:\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{opt.outf}rotation_experiment_{style}_{content}.png')\n",
    "            plt.close()\n",
    "\n",
    "            # Also save individual images\n",
    "            for idx, img in enumerate(images):\n",
    "                plt.imsave(f'{opt.outf}rotation_{style}_{content}_angle_{thetas[idx]}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                batchSize: 1                             \n",
      "              contentPath: data/content/                 \n",
      "                     cuda: True                          \n",
      "              decoder_dir: models/dec_r41.pth            \n",
      "                 fineSize: 256                           \n",
      "                    layer: r41                           \n",
      "                 loadSize: 256                           \n",
      "               matrixPath: models/r41.pth                \n",
      "                     outf: Artistic/translation/         \n",
      "                stylePath: data/style/                   \n",
      "                  vgg_dir: models/vgg_r41.pth            \n",
      "----------------- End -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_231082/2792762880.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vgg.load_state_dict(torch.load(opt.vgg_dir))\n",
      "/tmp/ipykernel_231082/2792762880.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dec.load_state_dict(torch.load(opt.decoder_dir))\n",
      "/tmp/ipykernel_231082/2792762880.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  matrix.load_state_dict(torch.load(opt.matrixPath))\n",
      "Processing Styles:  71%|███████▏  | 15/21 [30:26<12:26, 124.34s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from libs.Matrix import MulLayer\n",
    "from libs.models import encoder3, encoder4, decoder3, decoder4\n",
    "from libs.utils import print_options\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.contentPath = \"data/content/\"\n",
    "        self.stylePath = \"data/style/\"\n",
    "        self.loadSize = 256\n",
    "        self.fineSize = 256\n",
    "        self.matrixPath = \"Matrices/\"\n",
    "        self.vgg_dir = 'models/vgg_r41.pth'\n",
    "        self.decoder_dir = 'models/dec_r41.pth'\n",
    "        self.layer = 'r41'\n",
    "        self.outf = \"Artistic/translation/\"\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "        self.batchSize = 1\n",
    "        self.matrixPath = 'models/r41.pth'\n",
    "\n",
    "def translate_matrix(matrix, x_shift, y_shift):\n",
    "    \"\"\"\n",
    "    Apply translation to the transformation matrix by shifting in the spatial dimensions.\n",
    "    \"\"\"\n",
    "    matrix_np = matrix.cpu().numpy() if matrix.is_cuda else matrix.numpy()\n",
    "    \n",
    "    # Shift along height and width (2nd and 3rd dimensions if 3D matrix)\n",
    "    translated = np.roll(matrix_np, shift=(x_shift, y_shift), axis=(1, 2))  # Apply translation to height and width\n",
    "    return torch.tensor(translated, device=matrix.device, dtype=matrix.dtype)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = Options()\n",
    "    print_options(opt)\n",
    "\n",
    "    os.makedirs(opt.outf, exist_ok=True)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    ################# MODEL #################\n",
    "    if opt.layer == 'r31':\n",
    "        vgg = encoder3()\n",
    "        dec = decoder3()\n",
    "    elif opt.layer == 'r41':\n",
    "        vgg = encoder4()\n",
    "        dec = decoder4()\n",
    "    matrix = MulLayer(opt.layer)\n",
    "    vgg.load_state_dict(torch.load(opt.vgg_dir))\n",
    "    dec.load_state_dict(torch.load(opt.decoder_dir))\n",
    "    matrix.load_state_dict(torch.load(opt.matrixPath))\n",
    "\n",
    "    ################# GPU #################\n",
    "    if opt.cuda:\n",
    "        vgg.cuda()\n",
    "        dec.cuda()\n",
    "        matrix.cuda()\n",
    "\n",
    "    content_files = [f for f in os.listdir(opt.contentPath) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    style_files = [f for f in os.listdir(opt.stylePath) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((opt.fineSize, opt.fineSize))\n",
    "    ])\n",
    "\n",
    "    # Define small translations\n",
    "    translations = [(x, y) for x in range(6) for y in range(6) if (x != 0 or y != 0)]\n",
    "\n",
    "    # Processing loop\n",
    "    for style in tqdm(style_files, desc=\"Processing Styles\"):\n",
    "        style_image = Image.open(os.path.join(opt.stylePath, style)).convert('RGB')\n",
    "        style_tensor = transform(style_image).unsqueeze(0)\n",
    "\n",
    "        for content in tqdm(content_files, desc=\"Processing Contents\", leave=False):\n",
    "            content_image = Image.open(os.path.join(opt.contentPath, content)).convert('RGB')\n",
    "            content_tensor = transform(content_image).unsqueeze(0)\n",
    "\n",
    "            contentV = torch.Tensor(1, 3, opt.fineSize, opt.fineSize).copy_(content_tensor)\n",
    "            styleV = torch.Tensor(1, 3, opt.fineSize, opt.fineSize).copy_(style_tensor)\n",
    "\n",
    "            if opt.cuda:\n",
    "                contentV = contentV.cuda()\n",
    "                styleV = styleV.cuda()\n",
    "\n",
    "            ################# FORWARD PASS WITH TRANSLATION #################\n",
    "            with torch.no_grad():\n",
    "                sF = vgg(styleV)\n",
    "                cF = vgg(contentV)\n",
    "\n",
    "                if opt.layer == 'r41':\n",
    "                    feature, transmatrix = matrix(cF[opt.layer], sF[opt.layer], trans=True)\n",
    "                else:\n",
    "                    feature, transmatrix = matrix(cF, sF, trans=True)\n",
    "\n",
    "                compress_content = matrix.compress(cF[opt.layer] if opt.layer == 'r41' else cF)\n",
    "                b, c, h, w = compress_content.size()\n",
    "                compress_content = compress_content.view(b, c, -1)\n",
    "\n",
    "                # Apply each translation and save images individually\n",
    "                for (x_shift, y_shift) in translations:\n",
    "                    translated_matrix = translate_matrix(transmatrix, x_shift, y_shift)\n",
    "                    \n",
    "                    transfeature = torch.bmm(translated_matrix, compress_content).view(b, matrix.matrixSize, h, w)\n",
    "                    out = matrix.unzip(transfeature)\n",
    "                    out = out + torch.mean(cF[opt.layer if opt.layer == 'r41' else cF], dim=(2, 3), keepdim=True)\n",
    "                    \n",
    "                    transfer_translated = dec(out).clamp(0, 1)\n",
    "                    img_numpy = transfer_translated.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "                    \n",
    "                    # Save each translated image with a title indicating translation amount\n",
    "                    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "                    ax.imshow(img_numpy)\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f'Translation=({x_shift}, {y_shift})')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'{opt.outf}{content}_style_{style}_translation_{x_shift}_{y_shift}.png')\n",
    "                    plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
